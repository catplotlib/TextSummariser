{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The code imports three modules: numpy, sent_tokenize from the nltk (Natural Language Toolkit) package, and the os module."
      ],
      "metadata": {
        "id": "vVt4d9ayQDZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y9lR1pukxIG",
        "outputId": "389c7f97-836b-4643-8c49-e07ab6c12cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0zuwA0697i-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1151dfa-1848-43ce-d98d-91d257e98290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "from nltk import sent_tokenize\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is reading the file 'glove.6B.100d.txt' using the utf8 encoding and assigning the result to the variable 'glove_file'. This file is a pre-trained Glove model with 100-dimensional word vectors."
      ],
      "metadata": {
        "id": "qHLdFbhEQR3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Glove model file\n",
        "glove_file = open('/content/drive/MyDrive/Final NLP/glove.6B.100d.txt', encoding = 'utf8')"
      ],
      "metadata": {
        "id": "lGFIDQZph1j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code reads the embedding file, and creates a dictionary called \"model\" where each word from the file is the key and its corresponding vector of floating point values is the value. The vector is created by splitting each line of the file issue by the space character and converting the resulting list of string values to floating point numbers."
      ],
      "metadata": {
        "id": "Z3Naa2zbQsoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = {}\n",
        "for line in glove_file:\n",
        "    split_line = line.split()\n",
        "    word = split_line[0]\n",
        "    embedding = np.array([float(val) for val in split_line[1:]])\n",
        "    model[word] = embedding"
      ],
      "metadata": {
        "id": "ZJkKIB21h2R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is performing abstractive summarization on a given text using Glove. It first tokenizes the text into individual sentences. Then, it finds the vector representation of each sentence by summing the vectors of each word in the sentence, and dividing by the number of words in the sentence. It then calculates the similarity matrix between all sentences, using dot products and norms. The sentences are ranked based on the sum of their similarity values, and the top k sentences are selected and added to the summary. The summary is returned as a string."
      ],
      "metadata": {
        "id": "Yu4ZV2HcQ_GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Abstractive summarization using Glove\n",
        "def summarization(text, k):\n",
        "    # Tokenization\n",
        "    sentences = sent_tokenize(text)\n",
        "    # Find the vector representation of each sentence\n",
        "    sentence_vectors = []\n",
        "    for sentence in sentences:\n",
        "        if len(sentence) != 0:\n",
        "            vector = sum([model[word] for word in sentence.split() if word in model])/(len(sentence.split())+0.001)\n",
        "        else:\n",
        "            vector = np.zeros(100)\n",
        "        sentence_vectors.append(vector)\n",
        "    # Calculate the similarity matrix\n",
        "    sim_mat = np.zeros([len(sentences),len(sentences)])\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(len(sentences)):\n",
        "            if i != j:\n",
        "                sim_mat[i][j] = np.dot(sentence_vectors[i],sentence_vectors[j])/(np.linalg.norm(sentence_vectors[i])*np.linalg.norm(sentence_vectors[j]))\n",
        "    # Create a ranking of sentences in descending order\n",
        "    ranking = np.zeros(len(sentences))\n",
        "    for i in range(len(sentences)):\n",
        "        ranking[i] = np.sum(sim_mat[i])\n",
        "    sorted_rankings = np.argsort(-1*ranking)\n",
        "    # Select the top K sentences\n",
        "    top_k_sentences = sorted_rankings[:k]\n",
        "    top_k_sentences.sort()\n",
        "    summary = \"\"\n",
        "    for index in top_k_sentences:\n",
        "        summary += sentences[index]\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "BtmSE_3sh4GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code reads the text file 'text.txt' using the utf8 encoding and saves it as the variable 'text'. It then uses a summarization function to summarize the text with a value of k = 3 and prints the resulting summary."
      ],
      "metadata": {
        "id": "lyY-RtnkRI2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the text file\n",
        "text = \"\"\"Dougie Freedman is on the verge of agreeing a new two-year deal to remain at Nottingham Forest. Freedman has stabilised Forest since he replaced cult hero Stuart Pearce and the club's owners are pleased with the job he has done at the City Ground. Dougie Freedman is set to sign a new deal at Nottingham Forest . Freedman has impressed at the City Ground since replacing Stuart Pearce in February . They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons.\"\"\"\n",
        "\n",
        "# Print the summary for the text\n",
        "k = 3\n",
        "summary = summarization(text, k)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keVGeU4lbgf5",
        "outputId": "13cf42e0-e8bf-464a-cbd8-94b04388108d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Freedman has stabilised Forest since he replaced cult hero Stuart Pearce and the club's owners are pleased with the job he has done at the City Ground.Dougie Freedman is set to sign a new deal at Nottingham Forest .That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "#tokenize the sentences\n",
        "sentences = word_tokenize(summary)\n",
        "\n",
        "#tokenize the text\n",
        "tok_text = word_tokenize(text)"
      ],
      "metadata": {
        "id": "YkbZadAxnjrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "bleu_score = sentence_bleu([sentences], tok_text)\n",
        "print(bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvrn9eRikTsN",
        "outputId": "646b56e1-5023-4e92-9d3a-7b262a5c2582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4663508209086473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate rouge score\n",
        "# !pip install rouge\n",
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary, text)\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "PLxBcGg1oiS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e84c92b-305f-4871-a9be-0b46f7a8f8df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n",
            "[{'rouge-1': {'r': 0.6666666666666666, 'p': 1.0, 'f': 0.7999999952000001}, 'rouge-2': {'r': 0.5894736842105263, 'p': 0.9824561403508771, 'f': 0.7368421005756578}, 'rouge-l': {'r': 0.6666666666666666, 'p': 1.0, 'f': 0.7999999952000001}}]\n"
          ]
        }
      ]
    }
  ]
}